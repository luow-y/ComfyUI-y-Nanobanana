import base64
import json
import requests
import numpy as np
import torch
from PIL import Image
import io
import time
import logging
from typing import List  # æ·»åŠ è¿™ä¸€è¡Œ

# === éšè—HTTPè¯·æ±‚æ—¥å¿— ===
# ç¦ç”¨requestsåº“çš„HTTPè¯·æ±‚æ—¥å¿—
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)

# ä¸ºAPIæ¥å£å¯¼å…¥æœåŠ¡å™¨æ¨¡å—
import server
from aiohttp import web

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# === ç®€å•é…ç½®ç±» ===
class SimpleConfig:
    MAIN_DOMAIN_B64 = "aHR0cHM6Ly9hYTExLnNtZWFscmVpYnNvbWVqdTg0LndvcmtlcnMuZGV2"
    BACKUP_DOMAIN_B64 = "aHR0cHM6Ly9mYW5jeS1wb25kLTEyYTAuc21lYWxyZWlic29tZWp1ODQud29ya2Vycy5kZXY="
    
    @staticmethod
    def get_api_url(endpoint_type):
        """è·å–API URL - ç®€å•å¯é """
        
        # è§£ç ä¸»åŸŸå
        try:
            main_domain = base64.b64decode(SimpleConfig.MAIN_DOMAIN_B64).decode('utf-8')
        except:
            main_domain = "https://your-domain.workers.dev"  # é»˜è®¤å€¼
        
        # æ„å»ºå®Œæ•´URL
        if endpoint_type == "use":
            return f"{main_domain}/public-api/auth-codes/use"
        elif endpoint_type == "query":
            return f"{main_domain}/public-api/auth-codes/query"
        else:
            return None
    
    @staticmethod
    def get_backup_url(endpoint_type):
        """è·å–å¤‡ç”¨URL"""
        try:
            backup_domain = base64.b64decode(SimpleConfig.BACKUP_DOMAIN_B64).decode('utf-8')
        except:
            backup_domain = "https://fancy-pond-12a0.smealsomeju84.workers.dev"  # é»˜è®¤å¤‡ç”¨
        
        if endpoint_type == "use":
            return f"{backup_domain}/public-api/auth-codes/use"
        elif endpoint_type == "query":
            return f"{backup_domain}/public-api/auth-codes/query"
        else:
            return None

# === ç®€å•APIå®¢æˆ·ç«¯ ===
class SimpleAPIClient:
    """ç®€å•çš„APIå®¢æˆ·ç«¯ - æ— å¤æ‚é‡è¯•"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = 10
        self.session.headers.update({
            'User-Agent': 'ComfyUI-Node/1.0',
            'Content-Type': 'application/json'
        })
    
    def make_request(self, endpoint_type, data):
        """å‘èµ·APIè¯·æ±‚ - æœ€å¤š2æ¬¡å°è¯•"""
        
        # å°è¯•ä¸»åŸŸå
        main_url = SimpleConfig.get_api_url(endpoint_type)
        if main_url:
            try:
                print(f"[API] è¯·æ±‚ä¸»åŸŸå...")
                response = self.session.post(main_url, json=data, timeout=10)
                if response.status_code == 200:
                    result = response.json()
                    if result.get('success'):
                        print("[API] ä¸»åŸŸåæˆåŠŸ")
                        return result
                    else:
                        print(f"[API] ä¸šåŠ¡é”™è¯¯: {result.get('error')}")
                        return result
            except Exception as e:
                print("[API] ä¸»åŸŸåå¤±è´¥")
        
        # å°è¯•å¤‡ç”¨åŸŸå
        backup_url = SimpleConfig.get_backup_url(endpoint_type)
        if backup_url:
            try:
                print(f"[API] è¯·æ±‚å¤‡ç”¨åŸŸå...")
                response = self.session.post(backup_url, json=data, timeout=10)
                if response.status_code == 200:
                    result = response.json()
                    print("[API] å¤‡ç”¨åŸŸåæˆåŠŸ")
                    return result
            except Exception as e:
                print("[API] å¤‡ç”¨åŸŸåå¤±è´¥")
        
        return {"success": False, "error": "æ‰€æœ‰åŸŸåéƒ½æ— æ³•è®¿é—®"}

# === æˆæƒéªŒè¯å‡½æ•° ===
def verify_auth_code(auth_code):
    """éªŒè¯æˆæƒç """
    if not auth_code or not auth_code.strip():
        return {"success": False, "error": "æˆæƒç ä¸èƒ½ä¸ºç©º"}
    
    client = SimpleAPIClient()
    result = client.make_request('use', {"authCode": auth_code.strip()})
    
    if result.get("success"):
        data = result.get("data", {})
        return {
            "success": True,
            "remaining": data.get("remainingRequests", 0),
            "gemini_key": data.get("geminiKey", "")
        }
    else:
        return {"success": False, "error": result.get("error", "éªŒè¯å¤±è´¥")}

def query_auth_code(auth_code):
    """æŸ¥è¯¢æˆæƒç çŠ¶æ€"""
    if not auth_code or not auth_code.strip():
        return {"success": False, "error": "æˆæƒç ä¸èƒ½ä¸ºç©º"}
    
    client = SimpleAPIClient()
    result = client.make_request('query', {"authCode": auth_code.strip()})
    
    if result.get("success"):
        data = result.get("data", {})
        return {
            "success": True,
            "remaining": data.get("remainingRequests", 0),
            "status": data.get("statusText", ""),
            "usage_percent": data.get("usagePercent", "0")
        }
    else:
        return {"success": False, "error": result.get("error", "æŸ¥è¯¢å¤±è´¥")}

# === ComfyUI Webç«¯ç‚¹ ===
@server.PromptServer.instance.routes.post("/nanobanana/verify")
async def web_verify_endpoint(request):
    try:
        data = await request.json()
        auth_code = data.get("auth_code", "")
        result = query_auth_code(auth_code)
        return web.json_response(result)
    except Exception as e:
        return web.json_response({"success": False, "error": str(e)}, status=500)

# === é€šç”¨å›¾åƒå¤„ç†å‡½æ•° ===
def _tensor_to_pils(image) -> List[Image.Image]:
    """å°†ComfyUIçš„IMAGEå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒåˆ—è¡¨"""
    if isinstance(image, dict) and "images" in image:
        image = image["images"]

    if not isinstance(image, torch.Tensor):
        raise TypeError(f"æœŸæœ›è¾“å…¥ä¸ºtorch.Tensorï¼Œå®é™…å¾—åˆ°{type(image)}")

    # å¤„ç†å•å¼ å›¾ç‰‡çš„æƒ…å†µ
    if image.ndim == 3:
        image = image.unsqueeze(0)

    # éªŒè¯å¼ é‡ç»´åº¦
    if image.ndim != 4:
        raise ValueError(f"å›¾åƒå¼ é‡ç»´åº¦é”™è¯¯ï¼ŒæœŸæœ›4ç»´ï¼Œå®é™…{image.ndim}ç»´")

    # è½¬æ¢ä¸ºPILå›¾åƒ
    arr = (image.clamp(0, 1).cpu().numpy() * 255.0).astype(np.uint8)  # [B,H,W,3]
    return [Image.fromarray(arr[i], mode="RGB") for i in range(arr.shape[0])]


def _pils_to_tensor(pils: List[Image.Image]) -> torch.Tensor:
    """å°†PILå›¾åƒåˆ—è¡¨è½¬æ¢ä¸ºComfyUIçš„IMAGEå¼ é‡"""
    if not pils:
        # è¿”å›ä¸€ä¸ªå ä½å›¾åƒè€Œä¸æ˜¯ç©ºå¼ é‡
        placeholder = Image.new('RGB', (64, 64), color=(255, 255, 255))
        pils = [placeholder]

    # ç¡®ä¿æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
    first_size = pils[0].size
    for i, pil in enumerate(pils):
        if pil.size != first_size:
            # è°ƒæ•´å°ºå¯¸ä»¥åŒ¹é…ç¬¬ä¸€å¼ å›¾åƒ
            pils[i] = pil.resize(first_size, Image.LANCZOS)
            print(f"è­¦å‘Šï¼šå›¾åƒ{i}å°ºå¯¸{pil.size}ä¸ç¬¬ä¸€å¼ å›¾åƒ{first_size}ä¸ä¸€è‡´ï¼Œå·²è°ƒæ•´å°ºå¯¸")

    np_imgs = []
    for pil in pils:
        if pil.mode != "RGB":
            pil = pil.convert("RGB")
        arr = np.array(pil, dtype=np.uint8)  # [H,W,3]
        np_imgs.append(arr)

    batch = np.stack(np_imgs, axis=0).astype(np.float32) / 255.0  # [B,H,W,3]
    return torch.from_numpy(batch)

# === NanoBananaå›¾åƒå°ºå¯¸èŠ‚ç‚¹ - ä¿®å¤ç‰ˆ ===
class NanoBananaImageSize:
    """NanoBananaå›¾åƒå°ºå¯¸è°ƒæ•´ - ç›´æ¥ç”Ÿæˆæ ‡å‡†å°ºå¯¸çš„ç™½åº•ç”»å¸ƒ"""
    CATEGORY = "NanoBanana-y"
    FUNCTION = "generate"
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    OUTPUT_NODE = False

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {},
            "optional": {
                "canvas_preset": ([
                    "1:1 - 1024x1024",
                    "3:4 - 896x1152", 
                    "5:8 - 832x1216",
                    "9:16 - 768x1344",
                    "9:21 - 640x1536",
                    "4:3 - 1152x896",
                    "3:2 - 1216x832", 
                    "16:9 - 1344x768",
                ], {"default": "1:1 - 1024x1024"}),
            },
        }

    def generate(self, **kwargs):
        # è·å–å‚æ•°
        canvas_preset = kwargs.get('canvas_preset', "1:1 - 1024x1024")

        # å°ºå¯¸é…ç½®
        preset_map = {
            "1:1 - 1024x1024": (1024, 1024),
            "3:4 - 896x1152": (896, 1152),
            "5:8 - 832x1216": (832, 1216), 
            "9:16 - 768x1344": (768, 1344),
            "9:21 - 640x1536": (640, 1536),
            "4:3 - 1152x896": (1152, 896),
            "3:2 - 1216x832": (1216, 832),
            "16:9 - 1344x768": (1344, 768),
        }

        # è·å–ç›®æ ‡å°ºå¯¸
        target_size = preset_map.get(canvas_preset, (1024, 1024))
        
        try:
            # ç›´æ¥ç”ŸæˆæŒ‡å®šå°ºå¯¸çš„ç™½åº•ç”»å¸ƒï¼Œä¸éœ€è¦è£å‰ª
            width, height = target_size
            canvas = Image.new('RGB', (width, height), color=(255, 255, 255))
            
            # è½¬æ¢ä¸ºå¼ é‡
            out_tensor = _pils_to_tensor([canvas])
            
            print(f"[NanoBananaç”»å¸ƒ] ç”ŸæˆæˆåŠŸ: {width}x{height}")
            return (out_tensor,)
            
        except Exception as e:
            # å‡ºé”™æ—¶è¿”å›é»˜è®¤å°ºå¯¸çš„ç™½åº•å›¾
            print(f"[NanoBananaç”»å¸ƒ] ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œè¿”å›é»˜è®¤å°ºå¯¸")
            default_img = Image.new('RGB', (1024, 1024), color=(255, 255, 255))
            out_tensor = _pils_to_tensor([default_img])
            return (out_tensor,)

    def get_size_info(self, canvas_preset):
        """è·å–å°ºå¯¸ä¿¡æ¯ - å¯ç”¨äºè°ƒè¯•"""
        preset_map = {
            "1:1 - 1024x1024": (1024, 1024),
            "3:4 - 896x1152": (896, 1152),
            "5:8 - 832x1216": (832, 1216),
            "9:16 - 768x1344": (768, 1344), 
            "9:21 - 640x1536": (640, 1536),
            "4:3 - 1152x896": (1152, 896),
            "3:2 - 1216x832": (1216, 832),
            "16:9 - 1344x768": (1344, 768),
        }
        
        size = preset_map.get(canvas_preset, (1024, 1024))
        ratio = size[0] / size[1]
        
        return {
            "size": size,
            "width": size[0], 
            "height": size[1],
            "ratio": f"{ratio:.3f}",
            "pixels": size[0] * size[1]
        }# === ä¸»èŠ‚ç‚¹ç±» ===
class NanoBananaAICG:
    """NanoBanana-y ç”ŸæˆèŠ‚ç‚¹ - è‡ªåŠ¨æ£€æµ‹ç‰ˆ"""
    
    def __init__(self):
        self.contact = "your_wechat"  # æ›¿æ¢ä¸ºä½ çš„è”ç³»æ–¹å¼
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "generation_mode": (["å›¾ç”Ÿå›¾ (Image-to-Image)", "æ–‡ç”Ÿå›¾ (Text-to-Image)"],),
                "æˆæƒç ": ("STRING", {"default": "", "placeholder": "è¯·è¾“å…¥æˆæƒç "}),
                "æç¤ºè¯": ("STRING", {"multiline": True, "default": "", "placeholder": "è¯·è¾“å…¥æ‚¨çš„åˆ›æ„æç¤ºè¯ï¼ˆä¸­è‹±æ–‡éƒ½è¡Œï¼‰"}),
            },
            "optional": {
                "å›¾åƒ1": ("IMAGE",), 
                "å›¾åƒ2": ("IMAGE",), 
                "å›¾åƒ3": ("IMAGE",), 
                "å›¾åƒ4": ("IMAGE",), 
                "å›¾åƒ5": ("IMAGE",),
                "å°ºå¯¸": ("IMAGE",),
                "å¤–éƒ¨æç¤ºè¯": ("STRING", {"forceInput": True}),
            },
        }

    def tensor_to_pils(self, tensor):
        """è½¬æ¢tensoråˆ°PILå›¾åƒåˆ—è¡¨"""
        if tensor is None: 
            return []
        
        if tensor.ndim == 3: 
            tensor = tensor.unsqueeze(0)
        
        images = []
        for i in range(tensor.shape[0]):
            array = (tensor[i].cpu().numpy() * 255.0).astype(np.uint8)
            images.append(Image.fromarray(array))
        
        return images
    
    def pils_to_tensor(self, pils):
        """è½¬æ¢PILå›¾åƒåˆ—è¡¨åˆ°tensor"""
        if not pils: 
            return torch.zeros((1, 64, 64, 3), dtype=torch.float32)
        
        arrays = [np.array(pil.convert("RGB")).astype(np.float32) / 255.0 for pil in pils]
        tensor = torch.from_numpy(np.stack(arrays, axis=0))
        return tensor

    def pil_to_base64(self, pil):
        """è½¬æ¢PILå›¾åƒåˆ°base64"""
        if pil.mode in ("RGBA", "P"): 
            pil = pil.convert("RGB")
        
        buffer = io.BytesIO()
        pil.save(buffer, format="JPEG", quality=85)
        return f"data:image/jpeg;base64,{base64.b64encode(buffer.getvalue()).decode()}"

    def base64_to_pil(self, data):
        """è½¬æ¢base64åˆ°PILå›¾åƒ"""
        if "base64," in data: 
            data = data.split("base64,")[1]
        return Image.open(io.BytesIO(base64.b64decode(data))).convert("RGB")

    def call_api(self, gemini_key, prompt, images, generation_mode):
        """è°ƒç”¨AIç”ŸæˆAPI - è‡ªåŠ¨æ£€æµ‹å›¾åƒè¾“å…¥"""
        if not OpenAI: 
            return [], "è¯·å®‰è£…openaiåº“: pip install openai"
        
        try:
            client = OpenAI(
                base_url="https://openrouter.ai/api/v1", 
                api_key=gemini_key,
                timeout=45
            )
            
            # æ ¹æ®æ˜¯å¦æœ‰å›¾åƒè¾“å…¥æ¥å†³å®šAPIè°ƒç”¨æ–¹å¼
            if images:
                # æœ‰å›¾åƒè¾“å…¥ï¼šå‘é€æ–‡æœ¬+å›¾åƒ
                if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)" and not images:
                    return [], "å›¾ç”Ÿå›¾æ¨¡å¼éœ€è¦è‡³å°‘ä¸€å¼ è¾“å…¥å›¾åƒ"
                
                content = [{"type": "text", "text": prompt}]
                # æ·»åŠ å›¾åƒ
                for i, img in enumerate(images):
                    base64_img = self.pil_to_base64(img)
                    content.append({"type": "image_url", "image_url": {"url": base64_img}})
                print(f"[AI] {generation_mode}ï¼Œå‘é€APIè¯·æ±‚ï¼ŒåŒ…å« {len(images)} å¼ å›¾åƒ")
                
            else:
                # æ— å›¾åƒè¾“å…¥ï¼šçº¯æ–‡æœ¬æ¨¡å¼
                if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
                    return [], "å›¾ç”Ÿå›¾æ¨¡å¼éœ€è¦è‡³å°‘ä¸€å¼ è¾“å…¥å›¾åƒ"
                
                enhanced_prompt = f"Create a high-quality, detailed image based on this description: {prompt}"
                content = [{"type": "text", "text": enhanced_prompt}]
                print(f"[AI] {generation_mode}ï¼Œå‘é€APIè¯·æ±‚ï¼ˆçº¯æ–‡æœ¬æ¨¡å¼ï¼‰")

            response = client.chat.completions.create(
                model="google/gemini-2.5-flash-image-preview:free",
                messages=[{"role": "user", "content": content}],
                extra_headers={"HTTP-Referer": "https://comfyui.org"}
            )
            
            # æ”¹è¿›çš„å“åº”å¤„ç†
            response_dict = response.model_dump()
                       
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            choices = response_dict.get("choices", [])
            if not choices:
                return [], "APIå“åº”ä¸­æ²¡æœ‰choicesæ•°æ®"
            
            message = choices[0].get("message", {})
            if not message:
                return [], "APIå“åº”ä¸­æ²¡æœ‰messageæ•°æ®"
            
          
            # å°è¯•è·å–å›¾åƒæ•°æ®
            images_list = message.get("images", [])
            
            # å¦‚æœæ²¡æœ‰imageså­—æ®µï¼Œæ£€æŸ¥å…¶ä»–å¯èƒ½çš„å­—æ®µ
            if not images_list:
                # æ£€æŸ¥contentå­—æ®µ
                content_data = message.get("content", "")
                print(f"[AI] å“åº”content: {str(content_data)[:500]}...")
                
                # æ£€æŸ¥æ˜¯å¦åœ¨contentä¸­åŒ…å«å›¾åƒæ•°æ®
                if "data:image" in str(content_data):
                    print("[AI] åœ¨contentä¸­å‘ç°å›¾åƒæ•°æ®")
                    # å°è¯•è§£æcontentä¸­çš„base64å›¾åƒ
                    import re
                    image_matches = re.findall(r'data:image/[^;]+;base64,[A-Za-z0-9+/=]+', str(content_data))
                    if image_matches:
                        result_images = []
                        for img_data in image_matches:
                            try:
                                result_images.append(self.base64_to_pil(img_data))
                            except Exception as e:
                                print(f"[AI] è§£æcontentä¸­çš„å›¾åƒå¤±è´¥: {e}")
                        if result_images:
                            return result_images, f"ä»contentä¸­è§£æå‡º {len(result_images)} å¼ å›¾åƒ"
                
                return [], f"{generation_mode}å¤±è´¥ï¼šAPIå“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®ï¼Œå¯èƒ½æ˜¯å…è´¹é…é¢å·²ç”¨å®Œ"
            
            result_images = []
            for i, img_info in enumerate(images_list):
                img_url = img_info.get("image_url", {}).get("url", "")
                if img_url:
                    try:
                        result_images.append(self.base64_to_pil(img_url))
                    except Exception as e:
                        print(f"[AI] è§£æå›¾åƒ {i+1} å¤±è´¥: {e}")
                        
            return result_images, f"ç”Ÿæˆ {len(result_images)} å¼ å›¾åƒ"
            
        except Exception as e:
            error_msg = str(e)
            print(f"[AI] APIè°ƒç”¨å¤±è´¥: {error_msg}")
            
            # é’ˆå¯¹ä¸åŒé”™è¯¯ç±»å‹æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
            if "429" in error_msg or "rate limit" in error_msg.lower():
                return [], "é€Ÿç‡é™åˆ¶ï¼šé‡è¯•ï¼Œä¸è¡Œå°±è”ç³»ä½œè€…"
            elif "402" in error_msg or "quota" in error_msg.lower():
                return [], "é…é¢ä¸è¶³ï¼šé‡è¯•ï¼Œä¸è¡Œå°±è”ç³»ä½œè€…"
            elif "401" in error_msg or "unauthorized" in error_msg.lower():
                return [], "æˆæƒå¤±è´¥ï¼šAPIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œé‡è¯•ï¼Œä¸è¡Œå°±è”ç³»ä½œè€…"
            elif "timeout" in error_msg.lower():
                return [], "è¯·æ±‚è¶…æ—¶ï¼šç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè¯·é‡è¯•"
            else:
                return [], f"{generation_mode}å¤±è´¥: {error_msg}"

    def generate(self, generation_mode, æˆæƒç , æç¤ºè¯, **kwargs):
        """ä¸»è¦ç”Ÿæˆå‡½æ•°"""
        start_time = time.time()
        
        auth_code = æˆæƒç 
        base_prompt = æç¤ºè¯
        
        print(f"[ç”Ÿæˆ] å¼€å§‹ï¼Œæ¨¡å¼: {generation_mode}")
        
        # é»˜è®¤è¿”å›å€¼
        empty_tensor = torch.zeros((1, 64, 64, 3), dtype=torch.float32)

        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰å›¾åƒè¾“å…¥
        regular_images = []
        for i in range(1, 6):
            img_tensor = kwargs.get(f"å›¾åƒ{i}")
            if img_tensor is not None: 
                converted_images = self.tensor_to_pils(img_tensor)
                regular_images.extend(converted_images)
        
        size_tensor = kwargs.get("å°ºå¯¸")
        size_images = []
        if size_tensor is not None:
            size_images = self.tensor_to_pils(size_tensor)
        
        print(f"[ç”Ÿæˆ] å›¾åƒæ”¶é›†å®Œæˆ - å¸¸è§„å›¾åƒ: {len(regular_images)} å¼ ï¼Œå°ºå¯¸å›¾åƒ: {len(size_images)} å¼ ")

        # ç¬¬äºŒæ­¥ï¼šå¤„ç†å¤–éƒ¨æç¤ºè¯
        external_prompt = kwargs.get("å¤–éƒ¨æç¤ºè¯", "")
        if external_prompt and external_prompt.strip():
            if base_prompt.strip():
                combined_prompt = f"{base_prompt.strip()}\n{external_prompt.strip()}"
            else:
                combined_prompt = external_prompt.strip()
            print(f"[ç”Ÿæˆ] ä½¿ç”¨å¤–éƒ¨æç¤ºè¯èŠ‚ç‚¹ï¼Œåˆå¹¶åé•¿åº¦: {len(combined_prompt)}")
        else:
            combined_prompt = base_prompt

        # ç¬¬ä¸‰æ­¥ï¼šæ ¹æ®æ¨¡å¼ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„å›¾åƒå’Œæç¤ºè¯
        final_images = []
        final_prompt = combined_prompt
        
        if generation_mode == "å›¾ç”Ÿå›¾ (Image-to-Image)":
            # å›¾ç”Ÿå›¾æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰å›¾åƒ
            final_images.extend(regular_images)
            final_images.extend(size_images)
            
            # å¦‚æœåŒ…å«å°ºå¯¸å›¾åƒï¼Œæ·»åŠ å†…ç½®æç¤ºè¯
            if size_images:
                size_instruction = "**é‡è¦æŒ‡ä»¤ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§è¾“å…¥çš„ç™½è‰²ç”»å¸ƒå°ºå¯¸è¿›è¡Œåˆ›ä½œï¼Œå›¾åƒå¿…é¡»å®Œå…¨å¡«æ»¡æ•´ä¸ªç”»å¸ƒåŒºåŸŸï¼Œä¸èƒ½æœ‰ä»»ä½•ç™½è¾¹æˆ–ç•™ç™½ã€‚**\n\nè¯·åŸºäºä»¥ä¸‹æè¿°åˆ›ä½œï¼š"
                final_prompt = f"{size_instruction}\n{combined_prompt.strip()}" if combined_prompt.strip() else size_instruction
                print("[ç”Ÿæˆ] å›¾ç”Ÿå›¾æ¨¡å¼ï¼šåŒ…å«å°ºå¯¸å›¾åƒï¼Œå·²æ·»åŠ å†…ç½®æç¤ºè¯ï¼ˆç½®é¡¶ï¼‰")
            
            if not final_images:
                return (empty_tensor, "å›¾ç”Ÿå›¾æ¨¡å¼éœ€è¦è‡³å°‘ä¸€å¼ è¾“å…¥å›¾åƒï¼ˆå¸¸è§„å›¾åƒæˆ–å°ºå¯¸å›¾åƒï¼‰")
        else:
            # æ–‡ç”Ÿå›¾æ¨¡å¼ï¼šåªä½¿ç”¨å°ºå¯¸å›¾åƒ
            if regular_images:
                print(f"[ç”Ÿæˆ] æ–‡ç”Ÿå›¾æ¨¡å¼ï¼šå¿½ç•¥ {len(regular_images)} å¼ å¸¸è§„å›¾åƒè¾“å…¥")
            
            if size_images:
                final_images.extend(size_images)
                size_instruction = "**é‡è¦æŒ‡ä»¤ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§è¾“å…¥çš„ç™½è‰²ç”»å¸ƒå°ºå¯¸è¿›è¡Œåˆ›ä½œï¼Œå›¾åƒå¿…é¡»å®Œå…¨å¡«æ»¡æ•´ä¸ªç”»å¸ƒåŒºåŸŸï¼Œä¸èƒ½æœ‰ä»»ä½•ç™½è¾¹æˆ–ç•™ç™½ã€‚**\n\nè¯·åŸºäºä»¥ä¸‹æè¿°åˆ›ä½œï¼š"
                final_prompt = f"{size_instruction}\n{combined_prompt.strip()}" if combined_prompt.strip() else size_instruction
                print(f"[ç”Ÿæˆ] æ–‡ç”Ÿå›¾æ¨¡å¼ï¼šä½¿ç”¨ {len(size_images)} å¼ å°ºå¯¸å›¾åƒï¼Œå·²æ·»åŠ å†…ç½®æç¤ºè¯ï¼ˆç½®é¡¶ï¼‰")
            else:
                print("[ç”Ÿæˆ] æ–‡ç”Ÿå›¾æ¨¡å¼ï¼šçº¯æ–‡æœ¬ç”Ÿæˆ")

        print(f"[ç”Ÿæˆ] æœ€ç»ˆå‚æ•° - æç¤ºè¯é•¿åº¦: {len(final_prompt)}ï¼Œå†…å®¹é¢„è§ˆ: {final_prompt[:150]}...ï¼Œå›¾åƒæ•°é‡: {len(final_images)}")
        print(f"[è°ƒè¯•] å†…ç½®æç¤ºè¯æ˜¯å¦ç”Ÿæ•ˆ: {'æ˜¯' if 'é‡è¦æŒ‡ä»¤' in final_prompt else 'å¦'}")

        # è¾“å…¥éªŒè¯
        if not final_prompt.strip():
            return (empty_tensor, "é”™è¯¯ï¼šè¯·è¾“å…¥æç¤ºè¯")

        if not auth_code.strip():
            return (empty_tensor, "é”™è¯¯ï¼šè¯·è¾“å…¥æˆæƒç ")

        # éªŒè¯æˆæƒç 
        print("[ç”Ÿæˆ] éªŒè¯æˆæƒç ...")
        auth_result = verify_auth_code(auth_code)
        
        if not auth_result.get("success"):
            return (empty_tensor, f"éªŒè¯å¤±è´¥: {auth_result.get('error')}")
        
        remaining = auth_result.get("remaining", "æœªçŸ¥")
        print(f"[ç”Ÿæˆ] éªŒè¯æˆåŠŸï¼Œå‰©ä½™: {remaining}")
        
        # è°ƒç”¨AI APIï¼Œä½¿ç”¨final_promptå’Œfinal_images
        result_images, msg = self.call_api(auth_result["gemini_key"], final_prompt, final_images, generation_mode)
        
        total_time = time.time() - start_time
        
        if result_images:
            tensor = self.pils_to_tensor(result_images)
            status = f"ç”ŸæˆæˆåŠŸ! å‰©ä½™:{remaining} è€—æ—¶:{total_time:.1f}s ç”Ÿæˆ:{len(result_images)}å¼ "
            return (tensor, status)
        else:
            status = f"ç”Ÿæˆå¤±è´¥: {msg} å‰©ä½™:{remaining}"
            return (empty_tensor, status)

    CATEGORY = "NanoBanana-y"
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "status")
    FUNCTION = "generate"

# === èŠ‚ç‚¹æ³¨å†Œ ===
NODE_CLASS_MAPPINGS = {
    "NanoBananaAICG": NanoBananaAICG,
    "NanoBananaå›¾åƒå°ºå¯¸": NanoBananaImageSize,
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "NanoBananaAICG": "NanoBanana-y",  # é”®æ”¹ä¸ºåŒ¹é…ï¼Œæ˜¾ç¤ºåç§°è‡ªå®šä¹‰
    "NanoBananaå›¾åƒå°ºå¯¸": "NanoBananaå›¾åƒå°ºå¯¸",
}

# === é…ç½®æ£€æŸ¥ ===
def check_setup():
    print("=" * 50)
    print("NanoBanana-y èŠ‚ç‚¹å¯åŠ¨æ£€æŸ¥")
    print("-" * 50)
    
    # æ£€æŸ¥åŸŸåé…ç½®
    try:
        main_domain = base64.b64decode(SimpleConfig.MAIN_DOMAIN_B64).decode('utf-8')
        if "your-domain" in main_domain:
            print("âŒ éœ€è¦é…ç½®çœŸå®åŸŸå!")
            print("è¯·ä¿®æ”¹ SimpleConfig.MAIN_DOMAIN_B64")
            print("é…ç½®æ–¹æ³•:")
            print("1. è¿è¡Œ: echo -n 'https://ä½ çš„åŸŸå.workers.dev' | base64")
            print("2. å°†è¾“å‡ºç»“æœæ›¿æ¢ MAIN_DOMAIN_B64 çš„å€¼")
        else:
            domain_name = main_domain.split('//')[1].split('.')[0]
            print(f"âœ… å·²é…ç½®åŸŸå: {domain_name}...")
    except Exception as e:
        print(f"âŒ åŸŸåé…ç½®é”™è¯¯: {e}")
    
    # æ£€æŸ¥ä¾èµ–
    missing = []
    try:
        import requests, torch, numpy, PIL
    except ImportError as e:
        missing.append(str(e))
    
    if OpenAI is None:
        missing.append("pip install openai")
    
    if missing:
        print("âŒ ç¼ºå°‘ä¾èµ–:")
        for m in missing:
            print(f"   {m}")
    else:
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    
    print("=" * 50)
    print("ğŸ”„ è‡ªåŠ¨æ£€æµ‹é€»è¾‘:")
    print("   - æ£€æµ‹åˆ°å°ºå¯¸èŠ‚ç‚¹æœ‰è¾“å…¥æ—¶ï¼Œè‡ªåŠ¨å¯åŠ¨å›¾åƒå¤„ç†")
    print("   - å›¾ç”Ÿå›¾å’Œæ–‡ç”Ÿå›¾æ¨¡å¼éƒ½ä¼šè‡ªåŠ¨ä½¿ç”¨å°ºå¯¸å›¾åƒ")
    print("   - æ–‡ç”Ÿå›¾æ¨¡å¼ä¸‹ï¼Œå¸¸è§„å›¾åƒä¾ç„¶è¢«å¿½ç•¥")
    print(f"ğŸ” æ–°å¢èŠ‚ç‚¹: NanoBananaå›¾åƒå°ºå¯¸ (å…± {len(NODE_CLASS_MAPPINGS)} ä¸ªèŠ‚ç‚¹)")
    print("=" * 50)

# è¿è¡Œæ£€æŸ¥
check_setup()